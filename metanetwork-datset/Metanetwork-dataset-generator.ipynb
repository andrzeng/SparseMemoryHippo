{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f5d1cc-649c-43b3-b332-931784517703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df09a392-aedf-464b-a2dd-b1346d64ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class generates correlated memory vectors as decribed in (Benna, Fusi; 2021)\n",
    "class CorrelatedPatterns():\n",
    "    def __init__(self, \n",
    "                 L, #Length of each memory vector \n",
    "                 p, #Number of ancestors\n",
    "                 k, #Number of children per ancestor\n",
    "                 gamma): #Average overlap between child and ancestor. A value of one means each child is identical to its ancestor,\n",
    "                        #while a value of zero means each child is completely different from its ancestor.\n",
    "        self.L = L\n",
    "        self.p = p\n",
    "        self.k = k\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        #Create three arrays to store the ancestor vectors, the descendant (child) vectors, and the difference vectors\n",
    "        self.ancestors = []\n",
    "        self.descendants = []\n",
    "        self.differences = []\n",
    "        \n",
    "        #For purposes of PyTorch dataset creation, we will create two new lists that do not themselves contain lists\n",
    "        self.descendants_singlelist = []\n",
    "        self.differences_singlelist = []\n",
    "        \n",
    "        for _ancestorIndex in range(p):\n",
    "            \n",
    "            #Each ancestor is initialized randomly\n",
    "            ancestor = np.random.choice((0,1), size=(L))\n",
    "            self.ancestors.append(np.array(ancestor))\n",
    "            \n",
    "            self.descendants.append([])\n",
    "            #Initialize k descendants\n",
    "            for _descendantIndex in range(k):\n",
    "                descendant = torch.tensor([])\n",
    "                for __i in range(len(ancestor)):\n",
    "                    \n",
    "                    #With probability 1-gamma, the descendant memory is corrupted at this bit. \n",
    "                    if(random.uniform(0,1) < 1-gamma):\n",
    "                        descendant = torch.cat((descendant, torch.tensor([0 if random.uniform(0,1) < 0.5 else 1])))\n",
    "                    else: #Otherwise, the ancestor's memory at this bit is copied to the descendant.\n",
    "                        descendant = torch.cat((descendant, torch.tensor([ancestor[__i]])))\n",
    "                \n",
    "                #Save the memory\n",
    "                self.descendants[_ancestorIndex].append(descendant.clone().detach())\n",
    "                self.descendants_singlelist.append(descendant.clone().detach().reshape(1,-1))\n",
    "            \n",
    "            #Calculate the differences between the ancestor vectors and the child vectors\n",
    "            self.differences.append([])\n",
    "            for _descendantIndex in range(k):\n",
    "                self.differences[_ancestorIndex].append(torch.tensor(self.ancestors[_ancestorIndex]) - self.descendants[_ancestorIndex][_descendantIndex])\n",
    "                self.differences_singlelist.append((torch.tensor(self.ancestors[_ancestorIndex]) - self.descendants[_ancestorIndex][_descendantIndex]).reshape(1,-1))\n",
    "                \n",
    "        self.descendants_singlelist = torch.cat(self.descendants_singlelist)\n",
    "        self.differences_singlelist = torch.cat(self.differences_singlelist)\n",
    "\n",
    "#This subclass inherits the PyTorch Dataset class in order to create datasets of correlated memory.\n",
    "class SensoryData(Dataset):\n",
    "    def __init__(self, \n",
    "                 L,      #Length of each sample\n",
    "                 p,      #Number of parents\n",
    "                 k,      #Number of children per parent \n",
    "                 gamma   #Overlap between parent and children (1=identical, 0=no overlap)\n",
    "                ):\n",
    "        super().__init__()\n",
    "        c = CorrelatedPatterns(L, p, k, gamma)\n",
    "        memories = c.descendants_singlelist\n",
    "        \n",
    "        #Grab the memories generated by CorrelatedPatterns()\n",
    "        self.data = memories\n",
    "        self.x = memories\n",
    "        self.y = memories\n",
    "        self.n_samples = memories.shape[0]\n",
    "    \n",
    "    #Implement necessary helper functions\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5f9972-0d37-48ad-bc68-c261df2ca273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = SensoryData(100, 100, 1000, 0.6)\n",
    "#torch.save(data, \"dataset.pt\")\n",
    "data = torch.load(\"dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e6ede3-5733-4cf4-9cc8-c50366d1b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_inputs, #Number of input units\n",
    "                 n_hiddens): #Number of hidden units\n",
    "        super().__init__()\n",
    "        \n",
    "        self.eweight = nn.Parameter(torch.rand(n_hiddens, n_inputs), requires_grad=True)\n",
    "        #self.initial_weights = self.eweight.clone()\n",
    "        self.initial_state_dict = copy.deepcopy(self.state_dict())\n",
    "        \n",
    "        \n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hiddens = n_hiddens\n",
    "        \n",
    "    #Implement the forward pass\n",
    "    def forward(self, X):\n",
    "        X = torch.flatten(X, start_dim=1)\n",
    "        \n",
    "        self.encoded = F.linear(X, self.eweight)\n",
    "        self.hidden_activations = F.relu(self.encoded)\n",
    "        self.decoded = F.linear(self.hidden_activations, self.eweight.T)\n",
    "        \n",
    "        return self.decoded, self.hidden_activations\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f52ed2e-e8e2-42f6-9fd0-1307623a3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(100,40)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db5e9f82-64bc-413d-811f-f255453fa5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b55099b-01ae-49cc-a21a-dc9f4a90aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_array = []\n",
    "for i in range(30):\n",
    "    focus_array.append(next(iter(loader)))\n",
    "    \n",
    "def update_focus_array():\n",
    "    pop_item = focus_array.pop(0)\n",
    "    push_item = next(iter(loader))\n",
    "    \n",
    "    focus_array.append(push_item)\n",
    "    \n",
    "    return push_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e707bc-3e3f-469e-8a85-a37de1d74706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function written by Huidi Li\n",
    "def compute_gradmask(model, grads, ratio=0.1): \n",
    "    masks = []\n",
    "    for i, p in enumerate(model.parameters()):\n",
    "        grads_shape = grads[i].shape\n",
    "        grads_sorted, grads_sort_idx = torch.sort(torch.abs(grads[i]).flatten())\n",
    "        min_idx = int(ratio * len(grads_sorted))\n",
    "        mask = abs(grads[i])<grads_sorted[min_idx]\n",
    "        masks.append(mask.reshape(grads_shape))\n",
    "    return masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee5ac19f-3e79-4b4c-aacc-ace6d4edf9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "            model,\n",
    "            optimizer,\n",
    "            loss_function,\n",
    "            outer_loop_epochs=1000,\n",
    "            inner_loop_epochs=100, \n",
    "            alpha=0.5,\n",
    "            reset_ratio=0.2\n",
    "        ):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    initial_parameters = []\n",
    "    for param_ind, param in enumerate(model.parameters()):\n",
    "        initial_parameters.append(param)\n",
    "    \n",
    "    \n",
    "    weight_history = []\n",
    "    \n",
    "    for outer_epoch in range(outer_loop_epochs):\n",
    "        \n",
    "        e_item = update_focus_array()\n",
    "        \n",
    "        Xs = torch.Tensor()\n",
    "        Ys = torch.Tensor()\n",
    "        for i in range(len(focus_array)):\n",
    "            Xs = torch.cat([Xs, focus_array[i][0]])\n",
    "            Ys = torch.cat([Ys, focus_array[i][1]])\n",
    "        \n",
    "        model_gradients_ma = []\n",
    "        \n",
    "        \n",
    "        W_old = []\n",
    "        for param_ind, param in enumerate(model.parameters()):\n",
    "            W_old.append(copy.deepcopy(param))\n",
    "        \n",
    "        for inner_epoch in range(inner_loop_epochs):\n",
    "            \n",
    "            predicted_y, net_hidden_activity = model(Xs)\n",
    "            loss = loss_function(predicted_y, Ys)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            for param_ind, param in enumerate(model.parameters()):\n",
    "                if(inner_epoch == 0):\n",
    "                    model_gradients_ma.append(torch.abs(param.grad))\n",
    "                else:\n",
    "                    model_gradients_ma[param_ind] = alpha*torch.abs(param.grad) + (1-alpha)*model_gradients_ma[param_ind]\n",
    "       \n",
    "        \n",
    "        W_new = []\n",
    "        for param_ind, param in enumerate(model.parameters()):\n",
    "            W_new.append(copy.deepcopy(param))\n",
    "        \n",
    "        #Save weights\n",
    "        weight_history.append({'W_new': W_new, \n",
    "                               'e_item': e_item, \n",
    "                               'W_old': W_old})\n",
    "        \n",
    "        #Reset weights\n",
    "        mask = compute_gradmask(model, model_gradients_ma, ratio=reset_ratio)\n",
    "        state_dict = model.state_dict()\n",
    "        param_index = 0\n",
    "        for param_name, param_value in state_dict.items():\n",
    "            state_dict[param_name][mask[param_index]] = model.initial_state_dict[param_name][mask[param_index]]\n",
    "            param_index += 1\n",
    "            \n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "    return weight_history\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce0b403-ac94-4092-a1aa-c15d1f0dd097",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55648a9-2f26-4b63-9dd1-e987475f92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = train(model=model,\n",
    "      optimizer=optimizer,\n",
    "      loss_function=loss_function,\n",
    "      outer_loop_epochs=10,\n",
    "      inner_loop_epochs=64\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c333dced-0b90-48fe-9ea0-d01d83316478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W_new': [Parameter containing:\n",
       "  tensor([[ 0.6643,  0.0258,  0.2156,  ...,  0.6712,  0.6269,  0.6567],\n",
       "          [ 0.3130,  0.2565,  0.4083,  ...,  0.5354,  0.2436,  0.7186],\n",
       "          [ 0.3074,  0.1699,  0.6967,  ...,  0.3992,  0.5833,  0.3688],\n",
       "          ...,\n",
       "          [ 0.6793,  0.5628,  0.0343,  ...,  0.4536,  0.1579, -0.0436],\n",
       "          [ 0.8813,  0.7844,  0.5189,  ...,  0.7373,  0.7919,  0.7031],\n",
       "          [ 0.6702,  0.2972,  0.2329,  ...,  0.9228,  0.6751,  0.6576]],\n",
       "         requires_grad=True)],\n",
       " 'e_item': [tensor([[0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "           1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "           0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "           0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "           1., 0., 1., 0., 0., 1., 1., 0., 1., 0.]]),\n",
       "  tensor([[0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "           1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "           0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "           0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "           1., 0., 1., 0., 0., 1., 1., 0., 1., 0.]])],\n",
       " 'W_old': [Parameter containing:\n",
       "  tensor([[0.7249, 0.0864, 0.2761,  ..., 0.7318, 0.6875, 0.7173],\n",
       "          [0.3736, 0.3171, 0.4688,  ..., 0.5960, 0.3043, 0.7793],\n",
       "          [0.3679, 0.2304, 0.7571,  ..., 0.4597, 0.6439, 0.4294],\n",
       "          ...,\n",
       "          [0.7398, 0.6233, 0.0947,  ..., 0.5142, 0.2185, 0.0170],\n",
       "          [0.9419, 0.8449, 0.5794,  ..., 0.7978, 0.8524, 0.7636],\n",
       "          [0.7307, 0.3577, 0.2933,  ..., 0.9833, 0.7356, 0.7181]],\n",
       "         requires_grad=True)]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1959fb3d-c172-438b-a107-549687fe144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb72cee-28a1-470b-bec8-bbd18efc2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('weight_history', arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece6ab7-4e13-438a-8e17-f6e731c1db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Rough work starts below\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "bc926f2d-1d4e-4643-84d1-754d0073b372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1183,  0.4015,  0.0382,  ...,  0.5464,  0.6362,  0.6177],\n",
       "        [ 0.0605,  0.8527,  0.6117,  ...,  0.3146, -0.0758,  0.0246],\n",
       "        [ 0.7188,  0.5335,  0.7015,  ...,  0.4799,  0.1936,  0.7696],\n",
       "        ...,\n",
       "        [ 0.2808, -0.0324,  0.6383,  ...,  0.4616,  0.0205,  0.3546],\n",
       "        [-0.2984, -0.0422,  0.3502,  ..., -0.0270,  0.1248,  0.0226],\n",
       "        [ 0.7495,  0.8494, -0.0614,  ...,  0.2171, -0.3807,  0.0447]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "c074bdcf-8c2b-4757-9db8-fd042e3bfa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.load('weight_history.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "9ae2758c-6d9e-4d91-a07d-fb76156a4390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('eweight',\n",
       "              tensor([[0.4730, 0.4598, 0.1763,  ..., 0.7096, 0.9873, 0.7175],\n",
       "                      [0.1610, 0.9123, 0.6327,  ..., 0.3353, 0.0253, 0.0451],\n",
       "                      [0.8188, 0.5927, 0.7222,  ..., 0.5002, 0.2939, 0.7897],\n",
       "                      ...,\n",
       "                      [0.3417, 0.0275, 0.6592,  ..., 0.4821, 0.1452, 0.3750],\n",
       "                      [0.0950, 0.3385, 0.3902,  ..., 0.1427, 0.1639, 0.0621],\n",
       "                      [0.8307, 0.9285, 0.4003,  ..., 0.3872, 0.0826, 0.0645]]))])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.initial_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "88255ec9-8645-4995-b08a-ec76c9f92172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3200)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(output_data[0][0][0] == output_data[1][2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "34adcaa3-7db4-41a9-b10a-cfd55ed0f1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.3762e-01,  4.2061e-01,  5.8512e-02,  ...,  5.6629e-01,\n",
       "           6.5550e-01,  6.3742e-01],\n",
       "         [ 8.0628e-02,  8.7264e-01,  5.0915e-01,  ...,  1.6365e-01,\n",
       "          -5.5672e-02,  4.1318e-03],\n",
       "         [ 7.3861e-01,  5.5311e-01,  5.9947e-01,  ...,  2.9128e-01,\n",
       "           2.1330e-01,  7.0604e-01],\n",
       "         ...,\n",
       "         [ 3.0080e-01, -1.2610e-02,  2.8195e-01,  ...,  3.2624e-01,\n",
       "           4.0471e-02,  3.3377e-01],\n",
       "         [-2.7908e-01, -2.3132e-02,  3.7044e-01,  ..., -7.1716e-03,\n",
       "           1.4411e-01,  4.2338e-02],\n",
       "         [ 7.6895e-01,  8.6863e-01, -4.1126e-02,  ...,  2.3707e-01,\n",
       "          -3.6131e-01,  7.9244e-04]], requires_grad=True)]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce28521-170a-4bb1-8741-de307a64f5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b07e2479-f0f4-4755-aab1-b063fb8d2e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = compute_gradmask(model, grads)\n",
    "state_dict = model.state_dict()\n",
    "param_index = 0\n",
    "for param_name, param_value in state_dict.items():\n",
    "    state_dict[param_name][mask[param_index]] = model.initial_state_dict[param_name][mask[param_index]]\n",
    "    param_index += 1\n",
    "\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "c9f1f339-4934-46eb-aab0-0e5878cb3f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('eweight',\n",
       "              tensor([[0.4730, 0.4598, 0.1763,  ..., 0.7096, 0.9873, 0.7175],\n",
       "                      [0.1610, 0.9123, 0.6327,  ..., 0.3353, 0.0253, 0.0451],\n",
       "                      [0.8188, 0.5927, 0.7222,  ..., 0.5002, 0.2939, 0.7897],\n",
       "                      ...,\n",
       "                      [0.3417, 0.0275, 0.6592,  ..., 0.4821, 0.1452, 0.3750],\n",
       "                      [0.0950, 0.3385, 0.3902,  ..., 0.1427, 0.1639, 0.0621],\n",
       "                      [0.8307, 0.9285, 0.4003,  ..., 0.3872, 0.0826, 0.0645]]))])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d6988151-82f9-4901-b7fd-20c87a1b4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8eb6d563-a1e4-4184-98cc-d5f4de386ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd['eweight'][0][0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "529c8e3b-a5f1-47e6-80ae-463c4a25f510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('eweight',\n",
       "              tensor([[0.0000, 0.8409, 0.0066,  ..., 0.8660, 0.1656, 0.7450],\n",
       "                      [0.7339, 0.6887, 0.8721,  ..., 0.6556, 0.5670, 0.9647],\n",
       "                      [0.2318, 0.6499, 0.2764,  ..., 0.2299, 0.2761, 0.7626],\n",
       "                      ...,\n",
       "                      [0.9376, 0.8365, 0.7383,  ..., 0.6984, 0.7721, 0.1448],\n",
       "                      [0.4372, 0.6897, 0.2718,  ..., 0.3009, 0.0138, 0.2842],\n",
       "                      [0.6665, 0.7511, 0.4186,  ..., 0.6096, 0.6348, 0.4669]]))])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f6088c19-3f9a-4950-a701-37b9de282fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6ca17963-1b65-4b41-adc8-6b8477c0e042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('eweight',\n",
       "              tensor([[0.0000, 0.8409, 0.0066,  ..., 0.8660, 0.1656, 0.7450],\n",
       "                      [0.7339, 0.6887, 0.8721,  ..., 0.6556, 0.5670, 0.9647],\n",
       "                      [0.2318, 0.6499, 0.2764,  ..., 0.2299, 0.2761, 0.7626],\n",
       "                      ...,\n",
       "                      [0.9376, 0.8365, 0.7383,  ..., 0.6984, 0.7721, 0.1448],\n",
       "                      [0.4372, 0.6897, 0.2718,  ..., 0.3009, 0.0138, 0.2842],\n",
       "                      [0.6665, 0.7511, 0.4186,  ..., 0.6096, 0.6348, 0.4669]]))])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fa55eb96-4336-4a12-a213-2fe7f6e1e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(loader))\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "28810f67-6401-4da1-a066-8d95d9fe2707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " tensor([[825.4267, 341.2976, 790.4587,  ..., 844.1107, 304.6584, 813.0291],\n",
      "        [812.0034, 306.0449, 780.6472,  ..., 828.7575, 273.1901, 800.8862],\n",
      "        [822.4730, 327.8063, 788.8873,  ..., 840.4185, 292.6153, 810.5654],\n",
      "        ...,\n",
      "        [800.7516, 337.6969, 766.1525,  ..., 819.2385, 301.4442, 788.4847],\n",
      "        [832.0778, 329.2175, 798.3475,  ..., 850.1005, 293.8751, 820.1189],\n",
      "        [904.3927, 356.7924, 867.8372,  ..., 923.9250, 318.4898, 891.4323]])\n"
     ]
    }
   ],
   "source": [
    "predicted_y = model(sample[0])\n",
    "y = sample[1]\n",
    "loss = loss_function(predicted_y[0], y)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "grads = []\n",
    "\n",
    "for p_i, p in enumerate(model.parameters()):\n",
    "    print(p_i, '\\n', p.grad)\n",
    "    grads.append(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "45f082e3-8955-4838-84f6-988f0f18f248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[825.4267, 341.2976, 790.4587,  ..., 844.1107, 304.6584, 813.0291],\n",
       "         [812.0034, 306.0449, 780.6472,  ..., 828.7575, 273.1901, 800.8862],\n",
       "         [822.4730, 327.8063, 788.8873,  ..., 840.4185, 292.6153, 810.5654],\n",
       "         ...,\n",
       "         [800.7516, 337.6969, 766.1525,  ..., 819.2385, 301.4442, 788.4847],\n",
       "         [832.0778, 329.2175, 798.3475,  ..., 850.1005, 293.8751, 820.1189],\n",
       "         [904.3927, 356.7924, 867.8372,  ..., 923.9250, 318.4898, 891.4323]]),\n",
       " tensor([[825.4267, 341.2976, 790.4587,  ..., 844.1107, 304.6584, 813.0291],\n",
       "         [812.0034, 306.0449, 780.6472,  ..., 828.7575, 273.1901, 800.8862],\n",
       "         [822.4730, 327.8063, 788.8873,  ..., 840.4185, 292.6153, 810.5654],\n",
       "         ...,\n",
       "         [800.7516, 337.6969, 766.1525,  ..., 819.2385, 301.4442, 788.4847],\n",
       "         [832.0778, 329.2175, 798.3475,  ..., 850.1005, 293.8751, 820.1189],\n",
       "         [904.3927, 356.7924, 867.8372,  ..., 923.9250, 318.4898, 891.4323]])]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e57a290f-3fbc-4b4c-af0f-53aba7622792",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = compute_gradmask(model, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3d914a29-b297-404d-92c7-c73ff3123e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]])]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f7e10d5a-8776-4192-a433-1b7a5461c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd['eweight'][mask[0]] = model.initial_weights[mask[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "70089662-5fe1-4c44-950c-78e2a9f11b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd['eweight'][mask[0]] = torch.zeros(40,100)[mask[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a055b1e0-2e6a-4c10-b7f3-ad889dd4b487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3599)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(sd['eweight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "313ed97a-cedf-4b9e-b2ae-1029f3f4a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()['eweight'][mask[0]] = model.state_dict()['initial_weights'][mask[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "20163ca7-4453-44e5-b16d-0b6ebee2604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.state_dict()['initial_weights'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c9fecfb5-5751-4562-93f8-17b13e9bf466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['initial_weights'].zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9c405c89-1c39-48ac-bd10-6f9e77659827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5966, 0.5105, 0.3442,  ..., 0.2259, 0.5022, 0.2717],\n",
       "        [0.0634, 0.5499, 0.6019,  ..., 0.1523, 0.7488, 0.3010],\n",
       "        [0.1003, 0.1526, 0.2227,  ..., 0.7062, 0.9699, 0.6520],\n",
       "        ...,\n",
       "        [0.7800, 0.7819, 0.4833,  ..., 0.8788, 0.1001, 0.7249],\n",
       "        [0.0936, 0.9844, 0.5971,  ..., 0.1692, 0.5801, 0.8796],\n",
       "        [0.4447, 0.9624, 0.7964,  ..., 0.8942, 0.3114, 0.9893]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['initial_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e54d8-2def-43e1-9f0f-c3f1cd609a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "febd50ec-dc63-4e3e-a229-604d5bb57133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('eweight',\n",
       "              tensor([[0.2358, 0.1197, 0.3148,  ..., 0.5743, 0.9482, 0.7433],\n",
       "                      [0.4676, 0.1410, 0.6624,  ..., 0.3996, 0.1133, 0.0365],\n",
       "                      [0.4272, 0.5696, 0.3790,  ..., 0.2302, 0.1283, 0.0144],\n",
       "                      ...,\n",
       "                      [0.4981, 0.5285, 0.7370,  ..., 0.6440, 0.8810, 0.5669],\n",
       "                      [0.2353, 0.5997, 0.6826,  ..., 0.5670, 0.8261, 0.3660],\n",
       "                      [0.3919, 0.8457, 0.1804,  ..., 0.6236, 0.0643, 0.2066]])),\n",
       "             ('initial_weights',\n",
       "              tensor([[0.2358, 0.1197, 0.3148,  ..., 0.5743, 0.9482, 0.7433],\n",
       "                      [0.4676, 0.1410, 0.6624,  ..., 0.3996, 0.1133, 0.0365],\n",
       "                      [0.4272, 0.5696, 0.3790,  ..., 0.2302, 0.1283, 0.0144],\n",
       "                      ...,\n",
       "                      [0.4981, 0.5285, 0.7370,  ..., 0.6440, 0.8810, 0.5669],\n",
       "                      [0.2353, 0.5997, 0.6826,  ..., 0.5670, 0.8261, 0.3660],\n",
       "                      [0.3919, 0.8457, 0.1804,  ..., 0.6236, 0.0643, 0.2066]]))])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "73d19bc5-4c06-4320-b917-31b476e79c32",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [103], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model.parameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917abf0-66a7-4d1e-85b4-954fd7976008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d577cb-db85-4a29-aa54-4014a21ed53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_i, p in enumerate(model.parameters()):\n",
    "    print(p_i, '\\n', p.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
